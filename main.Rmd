---
title: "Google Analytics Customer Revenue Prediction"
output:
  html_notebook: default
  pdf_document: default
---

# Introdcution

A detailed analysis for Google Merchandise Store (also known as GStore, where Google swag is sold) customer dataset to predict revenue per customer. The goal is to enable marketing teams who analyze data on top of Google Analytics data to make more actionable operational changes and investment decisions.

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

# Loading and Exploring Data

```{r results='hide'}
library(tidyverse)
# loading data from CSV files.
train <- read_csv("./data/input/train.csv")
test <- read_csv("./data/input/test.csv")
```
```{r results='hide'}
glimpse(train)
glimpse(test)
```

There are 12 features:

* **fullVisitorId** - an unique identifier for each user of the Google Merchandise Store
* **channelGrouping** - the channel via which the user came to the Store
* **date** - the date on which the user visited the Store
* **device** - the specifications for the device used to access the Store
* **geoNetwork** - this section contains information about the geography of the user
* **sessionId** - an unique identifier for this visit to the store
* **socialEngagementType** - engagement type, either "Socially Engaged" or "Not Socially Engaged"
* **totals** - this section contains aggregate values across the session
* **trafficSource** - this section contains information about the Traffic Source from which the session originated
* **visitId** - an identifier for this session
* **visitNumber** - the session number for this user
* **visitStartTime** - the timestamp (POSIX).

The columns device, geoNetwork, trafficSource, and totals are in JSON format. 

# Parse JSON fields and spreed them to multiple varaiables

```{r echo=FALSE}
library(jsonlite)

flatten_json <- . %>%
  str_c(., collapse = ",") %>%
  str_c("[", .,"]") %>%
  fromJSON(flatten = T)

parse <- . %>%
  bind_cols(flatten_json(.$device)) %>%
  bind_cols(flatten_json(.$geoNetwork)) %>%
  bind_cols(flatten_json(.$trafficSource)) %>%
  bind_cols(flatten_json(.$totals)) %>%
  select(-device, -geoNetwork, -trafficSource, -totals)

train <- parse(train)
test <- parse(test)

```

## Removing the identification variables

We have two identification variables; sessionId, visitId, and fullVisitorId. We will keep the fullVisitorId as it is needed in our end result and will remove the others from training and testing data.

```{r results='hide'}
library(tidyverse)
train <- train %>% select(-sessionId, -visitId)
test <- test %>% select(-sessionId, -visitId)
```

As expected from the description the transactionRevenue variable is exist in the train data only. However, there is another variable -campaingCode- in test data is not exist in the train data. Let's remove it.
```{r}
setdiff(names(train), names(test))
train["campaignCode"] <- NULL
```


## Finding and Removing Constant Variables

```{r }
constant_features <- sapply(train, n_distinct)
cat("The constant features are: \n\n")
(deleted_cols = names(constant_features[constant_features == 1]))
train <- train %>% select(-one_of(deleted_cols))
test <- test %>% select(-one_of(deleted_cols))

rm(constant_features) 
rm(deleted_cols)

train %>%
  map_dfr(n_distinct) %>%
  gather() %>%
  ggplot(aes(reorder(key, -value), value)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  scale_y_log10(breaks = c(5, 50, 250, 500, 1000, 10000, 50000)) +
  geom_text(aes(label = value), vjust = 1.6, color = "white", size=3.5) +
  theme_minimal() +
  labs(x = "features", y = "Number of unique values") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

## Checking features format and its content

```{r}
glimpse(train)
```

During data observation, there is different representations for missing data. Let's convert them to NA.

```{r echo=FALSE}
is_na_val <- function(x) x %in% c("not available in demo dataset", "(not provided)","(not set)", "<NA>", "unknown.unknown","(none)") 

library(magrittr)
train %<>% mutate_all(funs(ifelse(is_na_val(.), NA, .)))
test %<>% mutate_all(funs(ifelse(is_na_val(.), NA, .)))

train %>%
  map_dfr(function(x) mean(is.na(x))) %>%
  gather() %>%
  filter(value > 0) %>%
  ggplot(aes(reorder(key, -value), value)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text(aes(label = paste(round(value, 3) * 100, "%")), vjust = .6, color = "white", size=3, hjust = 2) +
  theme_minimal() +
  coord_flip() + 
  labs(x = "features", y = "missing %") 

```
A lot of missing data in some variables!!


# Explore the target variable "transactionRevenue"

The transactionRevenue looks like it is multiplied by 10^6.

```{r}
y_rev <- as.numeric(train$transactionRevenue)
train$transactionRevenue <- NULL
summary(y_rev)
```
We can replce the *NA* with zero safely.
```{r echo=FALSE}
y_rev %<>% replace_na(0)
summary(y_rev)
```

```{r echo=FALSE}
as_tibble(log1p(y_rev[y_rev > 0])) %>%
  ggplot(aes(x = value)) + 
  geom_histogram(bins = 30, fill = "steelblue") + 
  labs(x = "non-zero transaction revenue") + 
  theme_minimal()
```

The target variable distribution is right-skewed and it multiplied by 1e6. So, log-transormation will be used.

## Revenue Vs Channel Group Relation
```{r echo=FALSE}
train %>%
  bind_cols(as_tibble(y_rev)) %>%
  group_by(channelGrouping) %>%
  summarise(n = n(), total_rev = sum(value)) %>%
  arrange(desc(total_rev)) %>%
  ggplot(aes(x = reorder(channelGrouping, -total_rev), y = total_rev)) +
  geom_point() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Channel Grouping", y = "Total Revenue") 
```

Both **Social** and **Affilites** channels transactions don't generate revnue. The major revenue comes from **Referral** and **Direct** channels.

## Revenue Vs visitNumber Relation
  
```{r result='asis', message=FALSE, warning=FALSE, echo=FALSE}
train %>%
  bind_cols(as_tibble(log1p(y_rev))) %>%
  group_by(visitNumber) %>%
  summarise(log_total_rev = sum(value)) %>%
  ggplot(aes(x = visitNumber, y = log_total_rev)) +
  geom_point() +
  theme_minimal() +
  scale_x_continuous(breaks=c(1, 3, 5, 10, 15, 25, 50, 100), limits=c(0, 105))
  #scale_y_continuous()
  
```

Most of the revnue comes from the first visit.

## Correlation between revenue and other features

There is a week positive relation with the following features.

```{r echo=FALSE}
library(lubridate)
m <- train %>% 
  mutate(y_rev = y_rev,
         date = ymd(date),
         year = year(date),
         month = month(date),
         day = day(date),
         hits = as.numeric(hits),
         pageviews = as.numeric(pageviews),
         bounces = as.numeric(bounces),
         newVisits = as.numeric(newVisits),
         isMobile = ifelse(isMobile, 1L, 0L),
         isTrueDirect = ifelse(isMobile, 1L, 0L)) %>% 
  mutate_all(funs(ifelse(is.na(.), 0, .))) %>% 
  select(-date, -fullVisitorId) %>% 
  mutate_if(is.character, factor) %>% 
  mutate_if(is.factor, fct_lump, prop = 0.01) %>%
  model.matrix(~ . - 1, .) %>% 
  cor() %>%
  as.data.frame() %>%
  select(y_rev) %>%
  data.table::as.data.table(keep.rownames=TRUE) %>%
  set_names(c("feature", "y_rev_cor")) %>%
  filter(abs(y_rev_cor) > 0.05) %>%
  arrange(desc(abs(y_rev_cor)))
  
  
```


# Visit and Revenue Distn over multiple categorical variables 

```{r echo=FALSE}
# -------- channelGrouping ----------------- 
train %>% 
  bind_cols(as_tibble(y_rev)) %>% 
  group_by(channelGrouping) %>% 
  summarize(visits = n(), total_revenue = sum(value)) %>% 
  ungroup() %>% 
  mutate(channelGrouping = reorder(channelGrouping, -visits)) %>% 
  data.table::melt(id.vars = c("channelGrouping")) %>% 
  ggplot(aes(channelGrouping, value, fill = variable)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  facet_wrap(~ variable, scales = "free") + 
  theme_minimal() +
  labs(x = "", y = "", title = "Visit and Revenue Distn over Channel Grouping") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position="none") 
# -------- browser ----------------- 
train %>% 
  bind_cols(as_tibble(y_rev)) %>% 
  mutate(browser = factor(browser) %>% fct_lump(prop=0.01)) %>% 
  group_by(browser) %>% 
  summarize(visits = n(), total_revenue = sum(value)) %>% 
  ungroup() %>% 
  mutate(browser = reorder(browser, -visits)) %>% 
  data.table::melt(id.vars = c("browser")) %>% 
  ggplot(aes(browser, value, fill = variable)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  facet_wrap(~ variable, scales = "free") + 
  theme_minimal() +
  labs(x = "", y = "", title = "Visit and Revenue Distn over browser") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position="none") 
# -------- operatingSystem ----------------- 
train %>% 
  bind_cols(as_tibble(y_rev)) %>% 
  mutate(operatingSystem = factor(operatingSystem) %>% fct_lump(prop=0.01)) %>%
  group_by(operatingSystem) %>% 
  summarize(visits = n(), total_revenue = sum(value)) %>% 
  ungroup() %>% 
  mutate(operatingSystem = reorder(operatingSystem, -visits)) %>% 
  data.table::melt(id.vars = c("operatingSystem")) %>% 
  ggplot(aes(operatingSystem, value, fill = variable)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  facet_wrap(~ variable, scales = "free") + 
  theme_minimal() +
  labs(x = "", y = "", title = "Visit and Revenue Distn over operatingSystem") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position="none") 
# -------- deviceCategory ----------------- 
train %>% 
  bind_cols(as_tibble(y_rev)) %>% 
  mutate(deviceCategory = factor(deviceCategory) %>% fct_lump(prop=0.01)) %>%
  group_by(deviceCategory) %>% 
  summarize(visits = n(), total_revenue = sum(value)) %>% 
  ungroup() %>% 
  mutate(deviceCategory = reorder(deviceCategory, -visits)) %>% 
  data.table::melt(id.vars = c("deviceCategory")) %>% 
  ggplot(aes(deviceCategory, value, fill = variable)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  facet_wrap(~ variable, scales = "free") + 
  theme_minimal() +
  labs(x = "", y = "", title = "Visit and Revenue Distn over deviceCategory") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position="none") 
# -------- country ----------------- 
train %>% 
  bind_cols(as_tibble(y_rev)) %>% 
  mutate(country = factor(country) %>% fct_lump(prop=0.025)) %>%
  group_by(country) %>% 
  summarize(visits = n(), total_revenue = sum(value)) %>% 
  ungroup() %>% 
  mutate(country = reorder(country, -visits)) %>% 
  data.table::melt(id.vars = c("country")) %>% 
  ggplot(aes(country, value, fill = variable)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  facet_wrap(~ variable, scales = "free") + 
  theme_minimal() +
  labs(x = "", y = "", title = "Visit and Revenue Distn over country") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position="none") 
# -------- city ----------------- 
train %>% 
  bind_cols(as_tibble(y_rev)) %>% 
  mutate(city = factor(city) %>% fct_lump(prop=0.01)) %>%
  group_by(city) %>% 
  summarize(visits = n(), total_revenue = sum(value)) %>% 
  ungroup() %>% 
  mutate(city = fct_explicit_na(city, na_level = "Other") %>% reorder(-visits)) %>%
  data.table::melt(id.vars = c("city")) %>% 
  ggplot(aes(city, value, fill = variable)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  facet_wrap(~ variable, scales = "free") + 
  theme_minimal() +
  labs(x = "", y = "", title = "Visit and Revenue Distn over city") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position="none") 

# -------- networkDomain ----------------- 
train %>% 
  bind_cols(as_tibble(y_rev)) %>% 
  mutate(networkDomain = factor(networkDomain) %>% fct_lump(prop=0.01)) %>%
  group_by(networkDomain) %>% 
  summarize(visits = n(), total_revenue = sum(value)) %>% 
  ungroup() %>% 
  mutate(networkDomain = fct_explicit_na(networkDomain, na_level = "Other") %>% reorder(-visits)) %>%
  data.table::melt(id.vars = c("networkDomain")) %>% 
  ggplot(aes(networkDomain, value, fill = variable)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  facet_wrap(~ variable, scales = "free") + 
  theme_minimal() +
  labs(x = "", y = "", title = "Visit and Revenue Distn over networkDomain") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position="none") 

# -------- medium ----------------- 
train %>% 
  bind_cols(as_tibble(y_rev)) %>% 
  mutate(medium = factor(medium) %>% fct_lump(prop=0.005)) %>%
  group_by(medium) %>% 
  summarize(visits = n(), total_revenue = sum(value)) %>% 
  ungroup() %>% 
  mutate(medium = fct_explicit_na(medium, na_level = "Other") %>% reorder(-visits)) %>%
  data.table::melt(id.vars = c("medium")) %>% 
  ggplot(aes(medium, value, fill = variable)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  facet_wrap(~ variable, scales = "free") + 
  theme_minimal() +
  labs(x = "", y = "", title = "Visit and Revenue Distn over medium") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position="none") 

```

**Conclusions**:

* Majority of visits comes from **Organic Search**, while the majority of revenue comes from **Referral** channels.
* Chrome is the dominant **browser** in both number of visits and generated revenue.
* Most of visits comes from devices that running Windows OS, whiel the majority of revenues comes from Mac devices. Chrome OS devices generats a noticed portion of revenue compared to its number of visits.
* Desktop still push the majority of visits and the generated revenue.
* Majority of visits and revenues come form the USA.
* Most visits and revenues comes from the Bay area and NY.
* Most of visits missing the network domain. Dot Net is the major one in the remaining revenue transactions.

# Categorical Features Interactions
```{r warning=FALSE, message=FALSE, echo=FALSE}
library(ggalluvial)
train %>% 
  select(country, networkDomain, browser, deviceCategory, channelGrouping) %>% 
  mutate(networkDomain = str_split(networkDomain, "\\.") %>% map(~ .x[[length(.x)]]) %>% unlist) %>% 
  mutate_all(factor) %>% 
  mutate_all(fct_lump, 4) %>% 
  bind_cols(tibble(y_rev = ifelse(y_rev == 0, "Zero", "Non-zero") %>% factor)) %>% 
  filter(y_rev == "Non-zero") %>%
  na.omit() %>% 
  group_by_all() %>% 
  count() %>% 
  ggplot(aes(y = n, 
             axis1 = country, axis2 = deviceCategory, axis3 = browser,   
             axis4 = channelGrouping, axis5 = networkDomain)) +
  geom_alluvium(aes(fill = y_rev), width = 1/12) +
  geom_stratum(width = 4/10, fill = "black", color = "grey") +
  geom_label(stat = "stratum", label.strata = TRUE) +
  theme_minimal() +
  scale_x_continuous(breaks = 1:5, labels = c("country", "deviceCategory", "browser",
                                               "channelGrouping", "networkDomain"))
```

The majority of revnues comes from this interaction **US -> Desktop -> Chrome -> Referral | Organic Search -> Net**

# Data Preparation Before Training 

```{r}

fullVisitorId <- test$fullVisitorId
id_df <- data.frame(fullVisitorId, stringsAsFactors = FALSE)

impute_missing_values <- function(df, na_level = "Missing") {
  imputed_col = data.frame(data = 1:nrow(df))
  df = as.data.frame(df)
  #loop over all variables 
  for(i in 1:ncol(df)) {
    if(is.factor(df[, i])) {
      df[, i] <- fct_lump(df[, i], prop = 0.025)
      df[, i] <- fct_explicit_na(df[, i], na_level = na_level)
    }else if(is.logical(df[, i]) & sum(is.na(df[ ,i]))) {
      df[, i] = replace_na(df[, i], "Missing")
      df[, i] = factor(df[, i])
    }else if(is.numeric(df[,i]) & sum(is.na(df[ ,i]))) {
      mean_before = mean(df[, i], na.rm = TRUE)
      var = ifelse(is.na(df[, i]), 1, 0)
      imputed_col = cbind(imputed_col, as.logical(var))
      names(imputed_col)[ncol(imputed_col)] = paste(names(df)[i], "imputed", sep = "_")
      df[,i] = replace_na(df[,i], mean_before)
    }
  }
  imputed_col[1] <- NULL
  if(length(imputed_col)) {
    for(i in 1:ncol(imputed_col)) {
      df = cbind(df, imputed_col[i])
    }
  }
  return(df)
}

grp_mean <- function(x, grp) ave(x, grp, FUN = function(x) mean(x, na.rm = TRUE))

prepare_for_modeling <- function(df) {
  df %>% 
  mutate(date = ymd(date),
         year = year(date) %>% factor(),
         month = year(date) %>% factor(),
         week = week(date) %>% factor(),
         day = day(date) %>% factor(),
         visit_hour = as.POSIXct(visitStartTime, origin = "1960-01-01") %>% hour %>% factor(),
         hits = as.integer(hits),
         pageviews = as.integer(pageviews),
         bounces = as.integer(bounces),
         newVisits = as.integer(newVisits),
         isMobile = ifelse(isMobile, 1L, 0L),
         isTrueDirect = ifelse(isTrueDirect, 1L, 0L),
         adwordsClickInfo.isVideoAd = ifelse(!adwordsClickInfo.isVideoAd, 0L, 1L)) %>% 
  select(-date, -fullVisitorId, -visitStartTime) %>% 
  mutate_if(is.character, factor) %>% 
  mutate(pageviews_mean_vn = grp_mean(pageviews, visitNumber),
         hits_mean_vn = grp_mean(hits, visitNumber),
         pageviews_mean_country = grp_mean(pageviews, country),
         hits_mean_country = grp_mean(hits, country),
         pageviews_mean_city = grp_mean(pageviews, city),
         hits_mean_city = grp_mean(hits, city)) %>%
    impute_missing_values()
}

train %<>% prepare_for_modeling()
test %<>% prepare_for_modeling()


```

# Submit
A function that predicts the natural log of the sum of all transactions per user.

```{r}
submit <- function(pred, output_path) {
  
  pred <- pred %>% 
    as_tibble() %>% 
    set_names("y") %>% 
    mutate(y = ifelse(y < 0, 0, expm1(y))) %>% 
    bind_cols(id_df) %>% 
    group_by(fullVisitorId) %>% 
    summarise(y = log1p(sum(y)))
  
  read_csv("./data/input/sample_submission.csv") %>%  
  left_join(pred, by = "fullVisitorId") %>% 
  mutate(PredictedLogRevenue = round(y, 5)) %>% 
  select(-y) %>% 
  write_csv(output_path)
}
```


# Random Forest
Using ranger implementation for Random Forest algorithm. 

```{r results='hide'}
library(ranger)
rf_model = ranger(y ~ ., data = train %>% mutate(y = log1p(y_rev)))
```


```{r results='hide'}
rf_model
summary(rf_model)
pred <- predict(rf_model, test)
submit(pred$predictions, "./data/output/ranger.csv")
```

This model scored on LB is 1.5846
